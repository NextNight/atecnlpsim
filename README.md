# Quora Question Pairs:    Embedding Feature    Text Mining Feature    Structural Feature（他们自己挖掘的Magic Feature）        并且他们也使用了Stacking的框架，并且使用固定的k-fold：        Stage1: 使用了Deep Learning，XGBoost，LightGBM，ExtraTree，Random Forest，KNN等300个模型。        Stage2: 用了手工特征和第一层的预测和深度学习模型的隐藏层，并且训练了150个模型。        Stage3: 使用了分别是带有L1和L2的两种线性模型。        Stage4: 将第三层的结果加权平均。    对比以后发现我们没有做LDA、LSI等特征，并且N-gram的粒度没有那么细（他们用了8-gram），    还有他们对Magic Feature的挖掘更加深入。    还有一点是他们的Deep Learning模型设计更加合理，    他们将筛选出来的手工特征也输入到深度学习模型当中，我觉得这也是他们取得好效果的关键。    因为显式地将手工特征输入给深度学习模型，相当于告诉“它你不用再学这些特征了，你去学其他的特征吧”，这样模型就能学到更多的语义信息。所以，我们跟他们的差距还是存在的。        Text Mining Feature，比如句子长度；两个句子的文本相似度，如N-gram的编辑距离，Jaccard距离等；两个句子共同的名词，动词，疑问词等。    Embedding Feature，预训练好的词向量相加求出句子向量，然后求两个句子向量的距离，比如余弦相似度、欧式距离等等。    Vector Space Feature，用TF-IDF矩阵来表示句子，求相似度。    Magic Feature，是Forum上一些选手通过思考数据集构造过程而发现的Feature，这种Feature往往与Label有强相关性，可以大大提高预测效果# 找出两个句子跟相似度有关的特征，            1、文本长度差        2、共同名次，动词，形容词，疑问词，标点符号个数        3、相似度：Jaccard距离，        4、相似度：TD-IDF N-gram 1-8距离（余玄相似度，欧氏距离）        5、相似度：公共词百分比        6、相似度：start是否相同        7、相似度：end是否相同        8、相似度：LDA        9、相似度：LSI        10、相似度：去掉公共子串的距离        11、相似度：去掉首尾的相似词占比        10、Embedding深度学习隐层        11、手动特征+句子-》深度隐层        12、句法分析:谓语